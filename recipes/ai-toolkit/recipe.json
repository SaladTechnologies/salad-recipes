{
  "container_template": {
    "autostartPolicy": true,
    "container": {
      "environmentVariables": {},
      "image": "saladtechnologies/ai-toolkit:cuda12.8-flux1-dev-kelpie",
      "imageCaching": true,
      "priority": "high",
      "resources": {
        "cpu": 4,
        "gpuClasses": ["851399fb-7329-4195-a042-d6514b28cf33"],
        "memory": 30720,
        "storageAmount": 53687091200
      }
    },
    "name": "",
    "replicas": 3,
    "restartPolicy": "always",
    "readme": "# AI Toolkit: Flux 1 Dev\n\nThis recipe provides an example implementation for using [AI Toolkit](https://github.com/ostris/ai-toolkit) to train LoRA models for the [Flux1-Dev](https://huggingface.co/black-forest-labs/FLUX.1-dev) image generation model. Note that this model is [not licensed for commercial use](https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev), so please ensure you have the appropriate rights to use it for your intended purpose.\n\n## Resources\n\n- [AI Toolkit](https://github.com/ostris/ai-toolkit)\n- [Kelpie API](https://kelpie.saladexamples.com/docs)\n- [Kelpie Worker Binary](https://github.com/SaladTechnologies/kelpie)\n- [Recipe Source](https://github.com/SaladTechnologies/salad-recipes/tree/master/recipes/ai-toolkit)\n- <Link url={`https://github.com/SaladTechnologies/salad-recipes/issues/new?title=AI%20Toolkit%20-%20Flux%201%20Dev&body=%3C%21---%20Please%20describe%20the%20issue%20you%20are%20having%20with%20this%20recipe%2C%20and%20include%20as%20much%20detail%20as%20possible%2C%20including%20any%20relevant%20logs.%20--%3E%0AImage%3A%20${props.container.image}`}>Report an Issue on GitHub</Link>\n\n## Preparing Your Dataset\n\nTo train a LoRA model using the AI Toolkit, you need to prepare your dataset in a specific structure, and upload that data to S3-compatible storage. The following steps outline how to set up your dataset for training:\n\n1. Create a directory named `data` in your project root.\n2. Create a folder inside the `data` directory named for a job id like `job-00001`.\n3. Inside that folder, create a `dataset` folder and place your training images inside, along with a `.txt` file for each image that contains a caption for the image of the same name. For example, if you have an image named `image1.jpg`, you should have a file named `image1.txt` with the caption for that image.\n4. Copy [this config file](https://github.com/ostris/ai-toolkit/blob/main/config/examples/train_lora_flux_24gb.yaml) to `data/job-00001/train.yaml` and make the following updates:\n   - Update `.config.name` to your job id (e.g., `job-00001`).\n   - Update `.config.datasets[0].folder_path` to `./dataset`\n   - Update `.model.name_or_path` to `/model`, as the model weights are included in the docker image we will be using.\n   - Update `.sample.prompts` to include the prompts you want to use for sampling. This is optional, but it can help you evaluate the quality of your model during training.\n   - Update `.config.save.max_step_saves_to_keep` to `2` to save only the most recent progress checkpoint, plus one backup in case of file corruption.\n\nThe folder structure should look like this:\n\n```text\ndata\n└── job-00001\n    ├── dataset\n    │   ├── 00001.jpg\n    │   ├── 00001.txt\n    │   ├── 00002.jpg\n    │   └── 00002.txt\n    └── train.yml\n```\n\n### Captioning Your Dataset\n\nIf you don't have captions for your dataset, you can use any vision-language model to generate the captions. In this example we use OpenAI's GPT-4.1-Nano model, (their least expensive model) to generate captions for our dataset. You can use the [generate-captions.py](https://github.com/SaladTechnologies/salad-recipes/blob/master/src/flux1-dev-ai-toolkit/generate-captions.py) script to generate captions for your dataset. The script will take a folder of images and generate captions for each image using the GPT-4.1-Nano model. The generated captions will be saved in the same folder as the images with the same name as the image, but with a `.txt` extension. You will need your OpenAI API key to use this script. You can set the `OPENAI_API_KEY` environment variable to your OpenAI API key.\n\n```bash\npython generate-captions.py data/job-00001/dataset\n```\n\n## Getting Your Container Group ID\n\n```bash\ncurl -X GET \\\n  --url https://api.salad.com/api/public/organizations/{organization_name}/projects/{project_name}/containers/{container_group_name} \\\n  --header 'Content-Type: application/json' \\\n  --header 'Salad-Api-Key: <api-key>'\n```\n\nThis will return a JSON object with the details of the container group, including the `.id` field.\n\n## Uploading Data And Queuing Jobs\n\nYou must upload your dataset to S3-compatible storage and queue jobs to the Kelpie API. The [prepare-and-queue-jobs.py](https://github.com/SaladTechnologies/salad-recipes/blob/master/src/flux1-dev-ai-toolkit/prepare-and-queue-jobs.py) script will do this for you. Modify the script to include your salad org and project name. You will need appropriate AWS credentials to access your S3-compatible storage, as well as your Salad API Key set in the environment variable `SALAD_API_KEY`. See the [Kelpie Docs](https://kelpie.saladexamples.com/docs) for more information about the Kelpie API.\n\n```bash\npython prepare-and-queue-jobs.py \\\n  data \\\n  s3://my-bucket/some-prefix \\\n  $container_group_id\n```\n\nThis will upload the dataset to your S3-compatible storage, and queue jobs to the Kelpie API. The script will also create a `kelpie_job.json` file in each job folder that contains the kelpie job id (different from your local job id, `job-00001`) and other information about the job.\n\nYou are encouraged to read the script to understand how it works, and how a kelpie job is structured.\n\nBriefly, a kelpie job consists of a `command`, some `arguments`, optional `environment` variables, and a `sync` configuration. The `sync` configuration tells kelpie what to download before starting a job, what to upload while the job executes, and what to upload when the job completes. In our case, this looks like this:\n\n- Before starting the job, kelpie will download the following files:\n  - The training config file\n  - The dataset folder\n  - Any previously uploaded progress checkpoints\n- While the job is running, kelpie will upload the following files:\n  - The training progress checkpoints\n  - Any images sampled during training\n- When the job completes, kelpie will upload the following files:\n  - The final model weights\n\n## Monitoring the Job\n\nYou can monitor the job using the Kelpie API. You can use the following command to get the status of the job:\n\n```bash\ncurl -X GET \\\n  --url https://kelpie.saladexamples.com/jobs/{job_id} \\\n  --header 'Content-Type: application/json' \\\n  --header 'Salad-Api-Key: <salad-api-key>' \\\n  --header 'Salad-Organization: <organization-name>' \\\n  --header 'Salad-Project: <project-name>'\n```\n\nMake sure to replace `{job_id}` with the job id of the kelpie job, and `<salad-api-key>` with your Salad API key.\n\nThis will return a JSON object with the details of the job, including the status, which machine had the job most recently, and how many heartbeats have been received.\n\nYou can also customize the `prepare-and-queue-jobs.py` script to include a webhook to be notified when the job completes.\n\n## Autoscaling\n\nKelpie has an optional autoscaling feature that automates adjusting replica count based on the number of queued jobs, including scale-to-zero when the queue is empty. This feature works through the Salad API, and requires adding the Kelpie user to your Salad Organization to grant the required API access. Currently that is me (shawn.rushefsky@salad.com).\n\nTo enable autoscaling, you can submit a request to the Kelpie API to establish scaling rules for your container group.\n\n```bash\ncurl -X POST \\\n  --url https://kelpie.saladexamples.com/scaling-rules \\\n  --header 'Content-Type: application/json' \\\n  --header 'Salad-Api-Key: <salad-api-key>' \\\n  --header 'Salad-Organization: <organization-name>' \\\n  --header 'Salad-Project: <project-name>' \\\n  --data '{\n    \"min_replicas\": 0,\n    \"max_replicas\": 10,\n    \"container_group_id\": \"<container-group-id>\"\n}'\n```\n\nMake sure to replace the placeholders with your Salad API key, organization name, project name, and the ID of the container group you created earlier.\nThis will create a scaling rule that will scale the container group to a minimum of 0 replicas and a maximum of 10 replicas. The scaling rules will be applied to all jobs submitted to the container group.\n\nThe Kelpie scaling algorithm works as follows:\n\n- Every 5 minutes, all scaling rules are evaluated.\n- The number of replicas in a container group is set to equal the number of queued or running jobs, up to the maximum number of replicas, and down to the minimum number of replicas.\n- If the desired number of replicas is 0, the container group will be stopped.\n- If the desired number of replicas is greater than 0 and the container group is not currently running, the container group will be started."
  },
  "form": {
    "title": "AI Toolkit - Flux 1 Dev",
    "description": "# AI Toolkit: Flux 1 Dev\n\nThis recipe provides an example implementation for using [AI Toolkit](https://github.com/ostris/ai-toolkit) to train LoRA models for the [Flux1-Dev](https://huggingface.co/black-forest-labs/FLUX.1-dev) image generation model. Note that this model is [not licensed for commercial use](https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev), so please ensure you have the appropriate rights to use it for your intended purpose.\n\nThis recipe uses [Kelpie](https://github.com/SaladTechnologies/kelpie) and the [Kelpie API](https://kelpie.saladexamples.com/docs) to manage the training jobs. Kelpie is a job queueing system that allows you to run long-running jobs on Salad's infrastructure, as well as manage data transfer between servers and s3-compatible storage.\n\nKelpie has an optional autoscaling feature that automates adjusting replica count based on the number of queued jobs, including scale-to-zero when the queue is empty.",
    "type": "object",
    "required": ["container_group_name", "aws_access_key_id", "aws_secret_access_key", "aws_region", "salad_project"],
    "properties": {
      "container_group_name": {
        "title": "Container Group Name",
        "description": "Required* Must be 2-63 lowercase letters, numbers, or hyphens. Cannot start with a number or start or end with a hyphen.",
        "type": "string",
        "maxLength": 63,
        "minLength": 2,
        "pattern": "^[a-z][a-z0-9-]{0,61}[a-z0-9]$"
      },
      "aws_access_key_id": {
        "title": "AWS Access Key ID",
        "description": "Required* Your AWS Access Key ID for S3 access.",
        "type": "string",
        "maxLength": 128,
        "minLength": 1
      },
      "aws_secret_access_key": {
        "title": "AWS Secret Access Key",
        "description": "Required* Your AWS Secret Access Key for S3 access.",
        "type": "string",
        "maxLength": 128,
        "minLength": 1
      },
      "aws_region": {
        "title": "AWS Region",
        "description": "Required* The AWS region where your S3 bucket is located.",
        "type": "string",
        "maxLength": 64,
        "minLength": 1,
        "default": "us-west-2"
      },
      "aws_endpoint_url": {
        "title": "AWS Endpoint URL",
        "description": "The endpoint URL for your S3 bucket, if using a custom endpoint.",
        "type": "string",
        "maxLength": 256,
        "minLength": 0
      },
      "salad_project": {
        "title": "Salad Project",
        "description": "Required* The Salad project to use for this worker.",
        "type": "string",
        "maxLength": 64,
        "minLength": 1
      }
    }
  },
  "patches": [
    [
      {
        "op": "copy",
        "from": "/input/autostart_policy",
        "path": "/output/autostartPolicy"
      },
      {
        "op": "copy",
        "from": "/input/replicas",
        "path": "/output/replicas"
      },
      {
        "op": "copy",
        "from": "/input/container_group_name",
        "path": "/output/name"
      },
      {
        "op": "copy",
        "from": "/input/aws_access_key_id",
        "path": "/output/container/environmentVariables/AWS_ACCESS_KEY_ID"
      },
      {
        "op": "copy",
        "from": "/input/aws_secret_access_key",
        "path": "/output/container/environmentVariables/AWS_SECRET_ACCESS_KEY"
      },
      {
        "op": "copy",
        "from": "/input/aws_region",
        "path": "/output/container/environmentVariables/AWS_REGION"
      },
      {
        "op": "copy",
        "from": "/input/aws_endpoint_url",
        "path": "/output/container/environmentVariables/AWS_ENDPOINT_URL"
      },
      {
        "op": "copy",
        "from": "/input/salad_project",
        "path": "/output/container/environmentVariables/SALAD_PROJECT"
      }
    ]
  ],
  "ui": {},
  "documentation_url": "https://github.com/SaladTechnologies/salad-recipes/tree/master/recipes/ai-toolkit",
  "short_description": "Deploy AI Toolkit with Flux 1 Dev",
  "workload_types": ["imageGeneration"]
}
