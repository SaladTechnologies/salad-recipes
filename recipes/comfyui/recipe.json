{
  "container_template": {
    "autostartPolicy": true,
    "container": {
      "environmentVariables": {},
      "image": "",
      "imageCaching": true,
      "priority": "high",
      "resources": {
        "cpu": 4,
        "gpuClasses": ["ed563892-aacd-40f5-80b7-90c9be6c759b"],
        "memory": 30720,
        "storageAmount": 1073741824
      }
    },
    "livenessProbe": {
      "failureThreshold": 50,
      "http": {
        "headers": [],
        "path": "/health",
        "port": 3000,
        "scheme": "http"
      },
      "initialDelaySeconds": 5,
      "periodSeconds": 2,
      "successThreshold": 1,
      "timeoutSeconds": 2
    },
    "name": "",
    "networking": {
      "auth": true,
      "clientRequestTimeout": 100000,
      "loadBalancer": "least_number_of_connections",
      "port": 3000,
      "protocol": "http",
      "serverResponseTimeout": 100000,
      "singleConnectionLimit": false
    },
    "replicas": 3,
    "restartPolicy": "always",
    "readme": "# ComfyUI API\n\n## Resources\n\n- <Link url={`https://${props.networking.dns}/docs`}>Swagger Docs</Link> (Needs auth if enabled)\n- [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api)\n- [ComfyUI](https://github.com/comfyanonymous/ComfyUI/)\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional optional parameters such as the webhook URL and image conversion options. A request may look something like:\n\n<Callout variation=\"warning\">This is not a complete request body, as it does not include a node that saves an output.</Callout>\n\n<CodeBlock language=\"json\">{`{\n  \"prompt\": {\n    \"1\": {\n      \"inputs\": {\n        \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n        \"upload\": \"image\"\n      },\n      \"class_type\": \"LoadImage\"\n    }\n  },\n  \"webhook\": \"https://example.com/webhook\",\n  \"convert_output\": {\n    \"format\": \"jpeg\",\n    \"options\": {\n      \"quality\": 80,\n      \"progressive\": true\n    }\n  }\n}`}</CodeBlock>\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your `prompt` must be a valid API-formatted ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n### Curl Example\n\n<Callout variation=\"note\">Requires `curl` and `jq` to be installed.</Callout>\n\nSave your request body to a file called `prompt.json` and run the following command:\n\n<Callout variation=\"note\">If you do not have auth enabled, you can omit the `Salad-Api-Key` header.</Callout>\n\n<CodeBlock language=\"bash\">{`curl -X POST https://${props.networking.dns}/prompt \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Salad-Api-Key: ${props.apiKey}\" \\\\\n  -d @prompt.json | jq -r .images[0] | base64 --decode > output.jpg\n`}</CodeBlock>\n\nThe generated image will be saved as `output.jpg` after decoding the base64 response.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n<CodeBlock language=\"json\">{`{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}`}</CodeBlock>\n",
    "readinessProbe": {
      "failureThreshold": 3,
      "http": {
        "headers": [],
        "path": "/ready",
        "port": 3000,
        "scheme": "http"
      },
      "initialDelaySeconds": 0,
      "periodSeconds": 2,
      "successThreshold": 1,
      "timeoutSeconds": 2
    }
  },
  "form": {
    "title": "ComfyUI API",
    "description": "Run popular image generation models with [ComfyUI](https://github.com/comfyanonymous/ComfyUI/) and [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api). Model weights are included in the container.\n\n<Callout variation=\"warning\">Ensure your use is permissible under whatever license applies to the model you are using.</Callout>\n\nThis recipe **DOES NOT** expose the ComfyUI web interface, it only provides the API interface via the [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api).\n\nThe ComfyUI API server is designed to be stateless, meaning that it does not store any state between requests. This allows the server to be scaled horizontally behind a load balancer, and to handle more requests by adding more instances of the server. The server uses a warmup workflow to ensure that ComfyUI is ready to accept requests, and to pre-load any required models. The server also self-hosts swagger docs and an openapi spec at `/docs`, which can be used to interact with the API.\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional parameters such as the webhook URL, S3 bucket and prefix, and image conversion options. A request may look something like:\n\n\n<Callout variation=\"warning\">This is not a complete request body, as it does not include a node that saves an output.</Callout>\n\n```json\n{\n  \"prompt\": {\n    \"1\": {\n      \"inputs\": {\n        \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n        \"upload\": \"image\"\n      },\n      \"class_type\": \"LoadImage\"\n    }\n  },\n  \"webhook\": \"https://example.com/webhook\",\n  \"convert_output\": {\n    \"format\": \"jpeg\",\n    \"options\": {\n      \"quality\": 80,\n      \"progressive\": true\n    }\n  }\n}\n```\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your prompt must be a valid ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n```json\n{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}\n```",
    "type": "object",
    "required": ["container_group_name", "container_image_model", "networking_auth"],
    "properties": {
      "container_group_name": {
        "type": "string",
        "title": "Container Group Name",
        "description": "Required* Must be 2-63 lowercase letters, numbers, or hyphens. Cannot start with a number or start or end with a hyphen.",
        "maxLength": 63,
        "minLength": 2,
        "pattern": "^[a-z][a-z0-9-]{0,61}[a-z0-9]$"
      },
      "container_image_model": {
        "title": "Model",
        "type": "string",
        "enum": ["dreamshaper8", "stablediffusionxl", "flux1schnell", "flux1dev", "stablediffusion35medium"],
        "default": "flux1dev"
      },
      "networking_auth": {
        "title": "Require Container Gateway Authentication",
        "description": "When enabled, requests must include a SaladCloud API Key. When disabled, any anonymous request will be allowed.",
        "type": "boolean",
        "default": true
      }
    }
  },
  "patches": [
    [
      {
        "op": "copy",
        "from": "/input/autostart_policy",
        "path": "/output/autostartPolicy"
      },
      {
        "op": "copy",
        "from": "/input/replicas",
        "path": "/output/replicas"
      },
      {
        "op": "copy",
        "from": "/input/container_group_name",
        "path": "/output/name"
      },
      {
        "op": "copy",
        "from": "/input/networking_auth",
        "path": "/output/networking/auth"
      }
    ],
    [
      {
        "op": "test",
        "path": "/input/container_image_model",
        "value": "dreamshaper8"
      },
      {
        "op": "add",
        "path": "/output/container/image",
        "value": "saladtechnologies/comfyui:comfy0.3.40-api1.9.0-torch2.7.1-cuda12.6-dreamshaper8"
      },
      {
        "op": "add",
        "path": "/output/readme",
        "value": "# ComfyUI API - Dreamshaper 8\n\n## Resources\n\n- <Link url={`https://${props.networking.dns}/docs`}>Swagger Docs</Link> (Needs auth if enabled)\n- [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api)\n- [ComfyUI](https://github.com/comfyanonymous/ComfyUI/)\n- [Dreamshaper 8](https://civitai.com/models/4384?modelVersionId=128713)\n- [Recipe Source](https://github.com/SaladTechnologies/salad-recipes/tree/master/src/dreamshaper8-comfyui)\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional optional parameters such as the webhook URL and image conversion options. A request may look something like:\n\n<CodeBlock language=\"json\">{`{\n    \"prompt\": {\n        \"3\": {\n            \"inputs\": {\n            \"seed\": 42,\n            \"steps\": 20,\n            \"cfg\": 8,\n            \"sampler_name\": \"euler\",\n            \"scheduler\": \"normal\",\n            \"denoise\": 1,\n            \"model\": [\n                \"4\",\n                0\n            ],\n            \"positive\": [\n                \"6\",\n                0\n            ],\n            \"negative\": [\n                \"7\",\n                0\n            ],\n            \"latent_image\": [\n                \"5\",\n                0\n            ]\n            },\n            \"class_type\": \"KSampler\",\n            \"_meta\": {\n            \"title\": \"KSampler\"\n            }\n        },\n        \"4\": {\n            \"inputs\": {\n            \"ckpt_name\": \"dreamshaper_8.safetensors\"\n            },\n            \"class_type\": \"CheckpointLoaderSimple\",\n            \"_meta\": {\n            \"title\": \"Load Checkpoint\"\n            }\n        },\n        \"5\": {\n            \"inputs\": {\n            \"width\": 512,\n            \"height\": 512,\n            \"batch_size\": 1\n            },\n            \"class_type\": \"EmptyLatentImage\",\n            \"_meta\": {\n            \"title\": \"Empty Latent Image\"\n            }\n        },\n        \"6\": {\n            \"inputs\": {\n            \"text\": \"beautiful scenery nature glass bottle landscape, , purple galaxy bottle,\",\n            \"clip\": [\n                \"4\",\n                1\n            ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n            \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"7\": {\n            \"inputs\": {\n            \"text\": \"text, watermark\",\n            \"clip\": [\n                \"4\",\n                1\n            ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n            \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"8\": {\n            \"inputs\": {\n            \"samples\": [\n                \"3\",\n                0\n            ],\n            \"vae\": [\n                \"4\",\n                2\n            ]\n            },\n            \"class_type\": \"VAEDecode\",\n            \"_meta\": {\n            \"title\": \"VAE Decode\"\n            }\n        },\n        \"9\": {\n            \"inputs\": {\n            \"filename_prefix\": \"ComfyUI\",\n            \"images\": [\n                \"8\",\n                0\n            ]\n            },\n            \"class_type\": \"SaveImage\",\n            \"_meta\": {\n            \"title\": \"Save Image\"\n            }\n        }\n    },\n    \"webhook\": \"https://example.com/webhook\",\n    \"convert_output\": {\n        \"format\": \"jpeg\",\n        \"options\": {\n            \"quality\": 80,\n            \"progressive\": true\n        }\n    }\n}`}</CodeBlock>\n\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your `prompt` must be a valid API-formatted ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n### Curl Example\n\n<Callout variation=\"note\">Requires `curl` and `jq` to be installed.</Callout>\n\nSave your request body to a file called `prompt.json` and run the following command:\n\n<Callout variation=\"note\">If you do not have auth enabled, you can omit the `Salad-Api-Key` header.</Callout>\n\n<CodeBlock language=\"bash\">{`curl -X POST https://${props.networking.dns}/prompt \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Salad-Api-Key: ${props.apiKey}\" \\\\\n  -d @prompt.json | jq -r .images[0] | base64 --decode > output.jpg\n`}</CodeBlock>\n\nThe generated image will be saved as `output.jpg` after decoding the base64 response.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n<CodeBlock language=\"json\">{`{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}`}</CodeBlock>\n"
      }
    ],
    [
      {
        "op": "test",
        "path": "/input/container_image_model",
        "value": "stablediffusionxl"
      },
      {
        "op": "add",
        "path": "/output/container/image",
        "value": "saladtechnologies/comfyui:comfy0.3.40-api1.9.0-torch2.7.1-cuda12.6-sdxl-with-refiner"
      },
      {
        "op": "add",
        "path": "/output/readme",
        "value": "# ComfyUI API - Stable Diffusion XL\n\n\n## Resources\n\n- <Link url={`https://${props.networking.dns}/docs`}>Swagger Docs</Link> (Needs auth if enabled)\n- [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api)\n- [ComfyUI](https://github.com/comfyanonymous/ComfyUI/)\n- [Stable Diffusion XL - Base](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)\n- [Stable Diffusion XL - Refiner](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)\n- [Recipe Source](https://github.com/SaladTechnologies/salad-recipes/tree/master/src/sdxl-with-refiner-comfyui)\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional optional parameters such as the webhook URL and image conversion options. A request may look something like:\n\n<CodeBlock language=\"json\">{`{\n    \"prompt\": {\n        \"4\": {\n            \"inputs\": {\n                \"ckpt_name\": \"sd_xl_base_1.0.safetensors\"\n            },\n            \"class_type\": \"CheckpointLoaderSimple\",\n            \"_meta\": {\n                \"title\": \"Load Checkpoint - BASE\"\n            }\n        },\n        \"5\": {\n            \"inputs\": {\n                \"width\": 1024,\n                \"height\": 1024,\n                \"batch_size\": 1\n            },\n            \"class_type\": \"EmptyLatentImage\",\n            \"_meta\": {\n                \"title\": \"Empty Latent Image\"\n            }\n        },\n        \"6\": {\n            \"inputs\": {\n                \"text\": \"evening sunset scenery blue sky nature, glass bottle with a galaxy in it\",\n                \"clip\": [\n                    \"4\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"7\": {\n            \"inputs\": {\n                \"text\": \"text, watermark\",\n                \"clip\": [\n                    \"4\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"10\": {\n            \"inputs\": {\n                \"add_noise\": \"enable\",\n                \"noise_seed\": 721897303308196,\n                \"steps\": 25,\n                \"cfg\": 8,\n                \"sampler_name\": \"euler\",\n                \"scheduler\": \"normal\",\n                \"start_at_step\": 0,\n                \"end_at_step\": 20,\n                \"return_with_leftover_noise\": \"enable\",\n                \"model\": [\n                    \"4\",\n                    0\n                ],\n                \"positive\": [\n                    \"6\",\n                    0\n                ],\n                \"negative\": [\n                    \"7\",\n                    0\n                ],\n                \"latent_image\": [\n                    \"5\",\n                    0\n                ]\n            },\n            \"class_type\": \"KSamplerAdvanced\",\n            \"_meta\": {\n                \"title\": \"KSampler (Advanced) - BASE\"\n            }\n        },\n        \"11\": {\n            \"inputs\": {\n                \"add_noise\": \"disable\",\n                \"noise_seed\": 0,\n                \"steps\": 25,\n                \"cfg\": 8,\n                \"sampler_name\": \"euler\",\n                \"scheduler\": \"normal\",\n                \"start_at_step\": 20,\n                \"end_at_step\": 10000,\n                \"return_with_leftover_noise\": \"disable\",\n                \"model\": [\n                    \"12\",\n                    0\n                ],\n                \"positive\": [\n                    \"15\",\n                    0\n                ],\n                \"negative\": [\n                    \"16\",\n                    0\n                ],\n                \"latent_image\": [\n                    \"10\",\n                    0\n                ]\n            },\n            \"class_type\": \"KSamplerAdvanced\",\n            \"_meta\": {\n                \"title\": \"KSampler (Advanced) - REFINER\"\n            }\n        },\n        \"12\": {\n            \"inputs\": {\n                \"ckpt_name\": \"sd_xl_refiner_1.0.safetensors\"\n            },\n            \"class_type\": \"CheckpointLoaderSimple\",\n            \"_meta\": {\n                \"title\": \"Load Checkpoint - REFINER\"\n            }\n        },\n        \"15\": {\n            \"inputs\": {\n                \"text\": \"evening sunset scenery blue sky nature, glass bottle with a galaxy in it\",\n                \"clip\": [\n                    \"12\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"16\": {\n            \"inputs\": {\n                \"text\": \"text, watermark\",\n                \"clip\": [\n                    \"12\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"17\": {\n            \"inputs\": {\n                \"samples\": [\n                    \"11\",\n                    0\n                ],\n                \"vae\": [\n                    \"12\",\n                    2\n                ]\n            },\n            \"class_type\": \"VAEDecode\",\n            \"_meta\": {\n                \"title\": \"VAE Decode\"\n            }\n        },\n        \"19\": {\n            \"inputs\": {\n                \"filename_prefix\": \"ComfyUI\",\n                \"images\": [\n                    \"17\",\n                    0\n                ]\n            },\n            \"class_type\": \"SaveImage\",\n            \"_meta\": {\n                \"title\": \"Save Image\"\n            }\n        }\n    },\n    \"webhook\": \"https://example.com/webhook\",\n    \"convert_output\": {\n        \"format\": \"jpeg\",\n        \"options\": {\n            \"quality\": 80,\n            \"progressive\": true\n        }\n    }\n}`}</CodeBlock>\n\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your `prompt` must be a valid API-formatted ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n### Curl Example\n\n<Callout variation=\"note\">Requires `curl` and `jq` to be installed.</Callout>\n\nSave your request body to a file called `prompt.json` and run the following command:\n\n<Callout variation=\"note\">If you do not have auth enabled, you can omit the `Salad-Api-Key` header.</Callout>\n\n<CodeBlock language=\"bash\">{`curl -X POST https://${props.networking.dns}/prompt \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Salad-Api-Key: ${props.apiKey}\" \\\\\n  -d @prompt.json | jq -r .images[0] | base64 --decode > output.jpg\n`}</CodeBlock>\n\nThe generated image will be saved as `output.jpg` after decoding the base64 response.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n<CodeBlock language=\"json\">{`{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}`}</CodeBlock>\n"
      }
    ],
    [
      {
        "op": "test",
        "path": "/input/container_image_model",
        "value": "flux1schnell"
      },
      {
        "op": "add",
        "path": "/output/container/image",
        "value": "saladtechnologies/comfyui:comfy0.3.40-api1.9.0-torch2.7.1-cuda12.6-flux1-schnell-fp8"
      },
      {
        "op": "add",
        "path": "/output/readme",
        "value": "# ComfyUI API - Flux.1 Schnell\n\n## Resources\n\n- <Link url={`https://${props.networking.dns}/docs`}>Swagger Docs</Link> (Needs auth if enabled)\n- [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api)\n- [ComfyUI](https://github.com/comfyanonymous/ComfyUI/)\n- [Flux.1 Schnell](https://huggingface.co/Comfy-Org/flux1-schnell/blob/main/flux1-schnell-fp8.safetensors)\n- [Recipe Source](https://github.com/SaladTechnologies/salad-recipes/tree/master/src/flux1-schnell-fp8-comfyui)\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional optional parameters such as the webhook URL and image conversion options. A request may look something like:\n\n<CodeBlock language=\"json\">{`{\n    \"prompt\": {\n        \"6\": {\n            \"inputs\": {\n                \"text\": \"a bottle with a beautiful rainbow galaxy inside it on top of a wooden table in the middle of a modern kitchen beside a plate of vegetables and mushrooms and a wine glasse that contains a planet earth with a plate with a half eaten apple pie on it\",\n                \"clip\": [\n                    \"30\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Positive Prompt)\"\n            }\n        },\n        \"8\": {\n            \"inputs\": {\n                \"samples\": [\n                    \"31\",\n                    0\n                ],\n                \"vae\": [\n                    \"30\",\n                    2\n                ]\n            },\n            \"class_type\": \"VAEDecode\",\n            \"_meta\": {\n                \"title\": \"VAE Decode\"\n            }\n        },\n        \"9\": {\n            \"inputs\": {\n                \"filename_prefix\": \"Flux\",\n                \"images\": [\n                    \"8\",\n                    0\n                ]\n            },\n            \"class_type\": \"SaveImage\",\n            \"_meta\": {\n                \"title\": \"Save Image\"\n            }\n        },\n        \"27\": {\n            \"inputs\": {\n                \"width\": 1024,\n                \"height\": 1024,\n                \"batch_size\": 1\n            },\n            \"class_type\": \"EmptySD3LatentImage\",\n            \"_meta\": {\n                \"title\": \"EmptySD3LatentImage\"\n            }\n        },\n        \"30\": {\n            \"inputs\": {\n                \"ckpt_name\": \"flux1-schnell-fp8.safetensors\"\n            },\n            \"class_type\": \"CheckpointLoaderSimple\",\n            \"_meta\": {\n                \"title\": \"Load Checkpoint\"\n            }\n        },\n        \"31\": {\n            \"inputs\": {\n                \"seed\": 1030319533692526,\n                \"steps\": 4,\n                \"cfg\": 1,\n                \"sampler_name\": \"euler\",\n                \"scheduler\": \"simple\",\n                \"denoise\": 1,\n                \"model\": [\n                    \"30\",\n                    0\n                ],\n                \"positive\": [\n                    \"6\",\n                    0\n                ],\n                \"negative\": [\n                    \"33\",\n                    0\n                ],\n                \"latent_image\": [\n                    \"27\",\n                    0\n                ]\n            },\n            \"class_type\": \"KSampler\",\n            \"_meta\": {\n                \"title\": \"KSampler\"\n            }\n        },\n        \"33\": {\n            \"inputs\": {\n                \"text\": \"\",\n                \"clip\": [\n                    \"30\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Negative Prompt)\"\n            }\n        }\n    },\n    \"webhook\": \"https://example.com/webhook\",\n    \"convert_output\": {\n        \"format\": \"jpeg\",\n        \"options\": {\n            \"quality\": 80,\n            \"progressive\": true\n        }\n    }\n}`}</CodeBlock>\n\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your `prompt` must be a valid API-formatted ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n### Curl Example\n\n<Callout variation=\"note\">Requires `curl` and `jq` to be installed.</Callout>\n\nSave your request body to a file called `prompt.json` and run the following command:\n\n<Callout variation=\"note\">If you do not have auth enabled, you can omit the `Salad-Api-Key` header.</Callout>\n\n<CodeBlock language=\"bash\">{`curl -X POST https://${props.networking.dns}/prompt \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Salad-Api-Key: ${props.apiKey}\" \\\\\n  -d @prompt.json | jq -r .images[0] | base64 --decode > output.jpg\n`}</CodeBlock>\n\nThe generated image will be saved as `output.jpg` after decoding the base64 response.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n<CodeBlock language=\"json\">{`{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}`}</CodeBlock>\n"
      }
    ],
    [
      {
        "op": "test",
        "path": "/input/container_image_model",
        "value": "flux1dev"
      },
      {
        "op": "add",
        "path": "/output/container/image",
        "value": "saladtechnologies/comfyui:comfy0.3.40-api1.9.0-torch2.7.1-cuda12.6-flux1-dev-fp8"
      },
      {
        "op": "add",
        "path": "/output/readme",
        "value": "# ComfyUI API - Flux.1 Dev\n\n## Resources\n\n- <Link url={`https://${props.networking.dns}/docs`}>Swagger Docs</Link> (Needs auth if enabled)\n- [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api)\n- [ComfyUI](https://github.com/comfyanonymous/ComfyUI/)\n- [Flux.1 Dev](https://huggingface.co/Comfy-Org/flux1-dev/blob/main/flux1-dev-fp8.safetensors)\n- [Recipe Source](https://github.com/SaladTechnologies/salad-recipes/tree/master/src/flux1-dev-fp8-comfyui)\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional optional parameters such as the webhook URL and image conversion options. A request may look something like:\n\n<CodeBlock language=\"json\">{`{\n    \"prompt\": {\n        \"6\": {\n            \"inputs\": {\n                \"text\": \"leafy green spaceship descending from orbit into a luch bio-organic cityscape. the sky is pale purple, and red storm clouds form in the distance, crackling with lightning.\",\n                \"clip\": [\n                    \"30\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Positive Prompt)\"\n            }\n        },\n        \"8\": {\n            \"inputs\": {\n                \"samples\": [\n                    \"31\",\n                    0\n                ],\n                \"vae\": [\n                    \"30\",\n                    2\n                ]\n            },\n            \"class_type\": \"VAEDecode\",\n            \"_meta\": {\n                \"title\": \"VAE Decode\"\n            }\n        },\n        \"9\": {\n            \"inputs\": {\n                \"filename_prefix\": \"ComfyUI\",\n                \"images\": [\n                    \"8\",\n                    0\n                ]\n            },\n            \"class_type\": \"SaveImage\",\n            \"_meta\": {\n                \"title\": \"Save Image\"\n            }\n        },\n        \"27\": {\n            \"inputs\": {\n                \"width\": 1024,\n                \"height\": 1024,\n                \"batch_size\": 1\n            },\n            \"class_type\": \"EmptySD3LatentImage\",\n            \"_meta\": {\n                \"title\": \"EmptySD3LatentImage\"\n            }\n        },\n        \"30\": {\n            \"inputs\": {\n                \"ckpt_name\": \"flux1-dev-fp8.safetensors\"\n            },\n            \"class_type\": \"CheckpointLoaderSimple\",\n            \"_meta\": {\n                \"title\": \"Load Checkpoint\"\n            }\n        },\n        \"31\": {\n            \"inputs\": {\n                \"seed\": 793373912447585,\n                \"steps\": 20,\n                \"cfg\": 1,\n                \"sampler_name\": \"euler\",\n                \"scheduler\": \"simple\",\n                \"denoise\": 1,\n                \"model\": [\n                    \"30\",\n                    0\n                ],\n                \"positive\": [\n                    \"35\",\n                    0\n                ],\n                \"negative\": [\n                    \"33\",\n                    0\n                ],\n                \"latent_image\": [\n                    \"27\",\n                    0\n                ]\n            },\n            \"class_type\": \"KSampler\",\n            \"_meta\": {\n                \"title\": \"KSampler\"\n            }\n        },\n        \"33\": {\n            \"inputs\": {\n                \"text\": \"\",\n                \"clip\": [\n                    \"30\",\n                    1\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Negative Prompt)\"\n            }\n        },\n        \"35\": {\n            \"inputs\": {\n                \"guidance\": 3.5,\n                \"conditioning\": [\n                    \"6\",\n                    0\n                ]\n            },\n            \"class_type\": \"FluxGuidance\",\n            \"_meta\": {\n                \"title\": \"FluxGuidance\"\n            }\n        }\n    },\n    \"webhook\": \"https://example.com/webhook\",\n    \"convert_output\": {\n        \"format\": \"jpeg\",\n        \"options\": {\n            \"quality\": 80,\n            \"progressive\": true\n        }\n    }\n}`}</CodeBlock>\n\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your `prompt` must be a valid API-formatted ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n### Curl Example\n\n<Callout variation=\"note\">Requires `curl` and `jq` to be installed.</Callout>\n\nSave your request body to a file called `prompt.json` and run the following command:\n\n<Callout variation=\"note\">If you do not have auth enabled, you can omit the `Salad-Api-Key` header.</Callout>\n\n<CodeBlock language=\"bash\">{`curl -X POST https://${props.networking.dns}/prompt \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Salad-Api-Key: ${props.apiKey}\" \\\\\n  -d @prompt.json | jq -r .images[0] | base64 --decode > output.jpg\n`}</CodeBlock>\n\nThe generated image will be saved as `output.jpg` after decoding the base64 response.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n<CodeBlock language=\"json\">{`{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}`}</CodeBlock>\n"
      }
    ],
    [
      {
        "op": "test",
        "path": "/input/container_image_model",
        "value": "stablediffusion35medium"
      },
      {
        "op": "add",
        "path": "/output/container/image",
        "value": "saladtechnologies/comfyui:comfy0.3.40-api1.9.0-torch2.7.1-cuda12.6-sd3.5-medium"
      },
      {
        "op": "add",
        "path": "/output/readme",
        "value": "# ComfyUI API - Stable Diffusion 3.5 Medium\n\n## Resources\n\n- <Link url={`https://${props.networking.dns}/docs`}>Swagger Docs</Link> (Needs auth if enabled)\n- [ComfyUI API](https://github.com/SaladTechnologies/comfyui-api)\n- [ComfyUI](https://github.com/comfyanonymous/ComfyUI/)\n- [Stable Diffusion 3.5 Medium](https://huggingface.co/stabilityai/stable-diffusion-3.5-medium)\n- [Recipe Source](https://github.com/SaladTechnologies/salad-recipes/tree/master/src/sd3.5-medium-comfyui)\n\n## Request Format\n\nPrompts are submitted to the server via the `POST /prompt` endpoint, which accepts a JSON body containing the prompt graph, as well as any additional optional parameters such as the webhook URL and image conversion options. A request may look something like:\n\n<CodeBlock language=\"json\">{`{\n    \"prompt\": {\n        \"4\": {\n            \"inputs\": {\n                \"ckpt_name\": \"sd3.5_medium.safetensors\"\n            },\n            \"class_type\": \"CheckpointLoaderSimple\",\n            \"_meta\": {\n                \"title\": \"Load Checkpoint\"\n            }\n        },\n        \"6\": {\n            \"inputs\": {\n                \"text\": \"beautiful scenery nature glass bottle landscape, purple galaxy bottle,\",\n                \"clip\": [\n                    \"11\",\n                    0\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"8\": {\n            \"inputs\": {\n                \"samples\": [\n                    \"294\",\n                    0\n                ],\n                \"vae\": [\n                    \"4\",\n                    2\n                ]\n            },\n            \"class_type\": \"VAEDecode\",\n            \"_meta\": {\n                \"title\": \"VAE Decode\"\n            }\n        },\n        \"11\": {\n            \"inputs\": {\n                \"clip_name1\": \"clip_g.safetensors\",\n                \"clip_name2\": \"clip_l.safetensors\",\n                \"clip_name3\": \"t5xxl_fp8_e4m3fn.safetensors\"\n            },\n            \"class_type\": \"TripleCLIPLoader\",\n            \"_meta\": {\n                \"title\": \"TripleCLIPLoader\"\n            }\n        },\n        \"13\": {\n            \"inputs\": {\n                \"shift\": 3,\n                \"model\": [\n                    \"4\",\n                    0\n                ]\n            },\n            \"class_type\": \"ModelSamplingSD3\",\n            \"_meta\": {\n                \"title\": \"ModelSamplingSD3\"\n            }\n        },\n        \"67\": {\n            \"inputs\": {\n                \"conditioning\": [\n                    \"71\",\n                    0\n                ]\n            },\n            \"class_type\": \"ConditioningZeroOut\",\n            \"_meta\": {\n                \"title\": \"ConditioningZeroOut\"\n            }\n        },\n        \"68\": {\n            \"inputs\": {\n                \"start\": 0.1,\n                \"end\": 1,\n                \"conditioning\": [\n                    \"67\",\n                    0\n                ]\n            },\n            \"class_type\": \"ConditioningSetTimestepRange\",\n            \"_meta\": {\n                \"title\": \"ConditioningSetTimestepRange\"\n            }\n        },\n        \"69\": {\n            \"inputs\": {\n                \"conditioning_1\": [\n                    \"68\",\n                    0\n                ],\n                \"conditioning_2\": [\n                    \"70\",\n                    0\n                ]\n            },\n            \"class_type\": \"ConditioningCombine\",\n            \"_meta\": {\n                \"title\": \"Conditioning (Combine)\"\n            }\n        },\n        \"70\": {\n            \"inputs\": {\n                \"start\": 0,\n                \"end\": 0.1,\n                \"conditioning\": [\n                    \"71\",\n                    0\n                ]\n            },\n            \"class_type\": \"ConditioningSetTimestepRange\",\n            \"_meta\": {\n                \"title\": \"ConditioningSetTimestepRange\"\n            }\n        },\n        \"71\": {\n            \"inputs\": {\n                \"text\": \"\",\n                \"clip\": [\n                    \"11\",\n                    0\n                ]\n            },\n            \"class_type\": \"CLIPTextEncode\",\n            \"_meta\": {\n                \"title\": \"CLIP Text Encode (Prompt)\"\n            }\n        },\n        \"135\": {\n            \"inputs\": {\n                \"width\": 1024,\n                \"height\": 1024,\n                \"batch_size\": 1\n            },\n            \"class_type\": \"EmptySD3LatentImage\",\n            \"_meta\": {\n                \"title\": \"EmptySD3LatentImage\"\n            }\n        },\n        \"294\": {\n            \"inputs\": {\n                \"seed\": 998428620595727,\n                \"steps\": 20,\n                \"cfg\": 4.5,\n                \"sampler_name\": \"dpmpp_2m\",\n                \"scheduler\": \"sgm_uniform\",\n                \"denoise\": 1,\n                \"model\": [\n                    \"13\",\n                    0\n                ],\n                \"positive\": [\n                    \"6\",\n                    0\n                ],\n                \"negative\": [\n                    \"69\",\n                    0\n                ],\n                \"latent_image\": [\n                    \"135\",\n                    0\n                ]\n            },\n            \"class_type\": \"KSampler\",\n            \"_meta\": {\n                \"title\": \"KSampler\"\n            }\n        },\n        \"301\": {\n            \"inputs\": {\n                \"filename_prefix\": \"ComfyUI\",\n                \"images\": [\n                    \"8\",\n                    0\n                ]\n            },\n            \"class_type\": \"SaveImage\",\n            \"_meta\": {\n                \"title\": \"Save Image\"\n            }\n        }\n    },\n    \"webhook\": \"https://example.com/webhook\",\n    \"convert_output\": {\n        \"format\": \"jpeg\",\n        \"options\": {\n            \"quality\": 80,\n            \"progressive\": true\n        }\n    }\n}`}</CodeBlock>\n\n\n- Only the `prompt` field is required. The other fields are optional, and can be omitted if not needed.\n- Your `prompt` must be a valid API-formatted ComfyUI prompt graph, which is a JSON object where each key is a node ID, and the value is an object containing the node's inputs, class type, and optional metadata.\n- Your prompt must include a node that saves an output, such as a `SaveImage` node.\n\n### Curl Example\n\n<Callout variation=\"note\">Requires `curl` and `jq` to be installed.</Callout>\n\nSave your request body to a file called `prompt.json` and run the following command:\n\n<Callout variation=\"note\">If you do not have auth enabled, you can omit the `Salad-Api-Key` header.</Callout>\n\n<CodeBlock language=\"bash\">{`curl -X POST https://${props.networking.dns}/prompt \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -H \"Salad-Api-Key: ${props.apiKey}\" \\\\\n  -d @prompt.json | jq -r .images[0] | base64 --decode > output.jpg\n`}</CodeBlock>\n\nThe generated image will be saved as `output.jpg` after decoding the base64 response.\n\n## Image To Image Workflows\n\nThe ComfyUI API server supports image-to-image workflows, allowing you to submit an image and receive a modified version of that image in response. This is useful for tasks such as image inpainting, style transfer, and other image manipulation tasks.\n\nTo use image-to-image workflows, you can submit an image as a base64-encoded string, http(s) URL, or S3 URL. The server will automatically detect the input type and process the image accordingly. If you are using S3, you must customize the deployment to add your AWS credentials to the environment variables.\n\nHere's an example of doing this in a `LoadImage` node:\n\n<CodeBlock language=\"json\">{`{\n  \"inputs\": {\n    \"image\": \"https://salad-benchmark-assets.download/coco2017/train2017/000000000009.jpg\",\n    \"upload\": \"image\"\n  },\n  \"class_type\": \"LoadImage\",\n  \"_meta\": {\n    \"title\": \"Load Image\"\n  }\n}`}</CodeBlock>\n"
      }
    ]
  ],
  "ui": {
    "container_image_model": {
      "ui:enumNames": [
        "Dreamshaper 8",
        "Stable Diffusion XL",
        "Flux 1 Schnell",
        "Flux 1 Dev",
        "Stable Diffusion 3.5 Medium"
      ]
    },
    "networking_auth": {
      "ui:placeholder": "Authentication"
    }
  },
  "documentation_url": "https://docs.salad.com/products/recipes/overview",
  "short_description": "Run popular image generation models with ComfyUI and ComfyUI API.",
  "workload_types": ["imageGeneration"]
}
