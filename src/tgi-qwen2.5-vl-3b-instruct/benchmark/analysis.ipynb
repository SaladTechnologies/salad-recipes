{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2402400/3870526672.py:137: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(\"request_count\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gpu\": \"3090\",\n",
      "  \"cost\": {\n",
      "    \"high\": 0.266,\n",
      "    \"medium\": 0.21600000000000003,\n",
      "    \"low\": 0.16599999999999998,\n",
      "    \"batch\": 0.116\n",
      "  },\n",
      "  \"max_throughput\": 33.0,\n",
      "  \"vus_at_max_throughput\": 237.0,\n",
      "  \"avg_input_tokens_per_image\": 1438.3238708242393,\n",
      "  \"gpt4o_mini_price\": 37.0655607,\n",
      "  \"cost_per_image_at_peak_throughput\": 9.764309764309767e-06,\n",
      "  \"images_per_dollar_at_peak_throughput\": 102413.79310344825,\n",
      "  \"cost_of_whole_batch_at_peak_throughput\": 0.7025323232323234,\n",
      "  \"savings_vs_openai\": 52.75993641041713,\n",
      "  \"test_duration\": 3416.096383,\n",
      "  \"max_nodes\": 10.0,\n",
      "  \"num_images\": 71949\n",
      "}\n",
      "{\n",
      "  \"gpu\": \"4080\",\n",
      "  \"cost\": {\n",
      "    \"high\": 0.29600000000000004,\n",
      "    \"medium\": 0.246,\n",
      "    \"low\": 0.196,\n",
      "    \"batch\": 0.14600000000000002\n",
      "  },\n",
      "  \"max_throughput\": 51.36363636363637,\n",
      "  \"vus_at_max_throughput\": 280.0,\n",
      "  \"avg_input_tokens_per_image\": 1438.1196772041656,\n",
      "  \"gpt4o_mini_price\": 55.4497893,\n",
      "  \"cost_per_image_at_peak_throughput\": 7.895771878072763e-06,\n",
      "  \"images_per_dollar_at_peak_throughput\": 126650.06226650062,\n",
      "  \"cost_of_whole_batch_at_peak_throughput\": 0.8537461258603737,\n",
      "  \"savings_vs_openai\": 64.94880342106356,\n",
      "  \"test_duration\": 3423.911471,\n",
      "  \"max_nodes\": 10.0,\n",
      "  \"num_images\": 108127\n",
      "}\n",
      "{\n",
      "  \"gpu\": \"4090\",\n",
      "  \"cost\": {\n",
      "    \"high\": 0.316,\n",
      "    \"medium\": 0.276,\n",
      "    \"low\": 0.236,\n",
      "    \"batch\": 0.196\n",
      "  },\n",
      "  \"max_throughput\": 36.333333333333336,\n",
      "  \"vus_at_max_throughput\": 299.0,\n",
      "  \"avg_input_tokens_per_image\": 1438.5627495226522,\n",
      "  \"gpt4o_mini_price\": 38.4523428,\n",
      "  \"cost_per_image_at_peak_throughput\": 1.4984709480122322e-05,\n",
      "  \"images_per_dollar_at_peak_throughput\": 66734.69387755104,\n",
      "  \"cost_of_whole_batch_at_peak_throughput\": 1.147588990825688,\n",
      "  \"savings_vs_openai\": 33.507068390690655,\n",
      "  \"test_duration\": 3536.444856,\n",
      "  \"max_nodes\": 10.0,\n",
      "  \"num_images\": 76584\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import os\n",
    "\n",
    "price_file = \"../../../benchmark/prices.json\"\n",
    "with open(price_file) as f:\n",
    "    prices = json.load(f)\n",
    "\n",
    "vcpu_price = 0.004\n",
    "mem_gb_price = 0.001\n",
    "    \n",
    "def get_price_map():\n",
    "  price_map = {}\n",
    "  for gpu_obj in prices[\"items\"]:\n",
    "      gpu_name = gpu_obj[\"name\"].lower()\n",
    "      price_map[gpu_name] = {}\n",
    "      for price_obj in gpu_obj[\"prices\"]:\n",
    "          price_map[gpu_name][price_obj[\"priority\"]] = float(price_obj[\"price\"])\n",
    "  return price_map\n",
    "\n",
    "price_map = get_price_map()\n",
    "gpt4o_mini_price_per_million = {\n",
    "  \"input\": .15,\n",
    "  \"output\": .6\n",
    "}\n",
    "gpt4o_mini_token_multiplier = 2.0\n",
    "\n",
    "def get_df(gpu):\n",
    "    datafile = f\"{gpu}.jsonl\"\n",
    "    node_counts = f\"{gpu}-node-count.csv\"\n",
    "    test_config = f\"{gpu}-test-config.json\"\n",
    "\n",
    "    df_file = f\"{gpu}-df.csv\"\n",
    "    \n",
    "    with open(test_config) as f:\n",
    "        test_config = json.load(f)\n",
    "    \n",
    "    gpu_uuid = test_config[\"container\"][\"resources\"][\"gpu_classes\"][0]\n",
    "    gpu_obj = next((x for x in prices[\"items\"] if x[\"id\"] == gpu_uuid), None)\n",
    "    gpu_name = gpu_obj[\"name\"].lower()\n",
    "\n",
    "    cost = {}\n",
    "    for priority in price_map[gpu_name]:\n",
    "        cost[priority] = price_map[gpu_name][priority] + (vcpu_price * test_config[\"container\"][\"resources\"][\"cpu\"]) + (mem_gb_price * test_config[\"container\"][\"resources\"][\"memory\"] // 1024)\n",
    "\n",
    "\n",
    "    if os.path.exists(df_file):\n",
    "        return pl.read_csv(df_file), cost\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    with open(datafile) as f:\n",
    "        for line in f:\n",
    "            if not line:\n",
    "                continue\n",
    "            data = json.loads(line)\n",
    "            if \"data\" in data and \"time\" in data[\"data\"]:\n",
    "                data[\"data\"][\"time\"] = parser.isoparse(data[\"data\"][\"time\"])\n",
    "                all_results.append(data)\n",
    "\n",
    "    tz = all_results[0][\"data\"][\"time\"].tzinfo\n",
    "\n",
    "    with open(node_counts) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            time, count = row\n",
    "            if not time or not count:\n",
    "                continue\n",
    "            all_results.append({\n",
    "                \"type\": \"Point\",\n",
    "                \"metric\": \"node_count\",\n",
    "                \"data\": {\n",
    "                    \"time\": datetime.fromtimestamp(int(time), tz=tz),\n",
    "                    \"value\": int(count)\n",
    "                }\n",
    "            })\n",
    "\n",
    "    metrics = [\"http_req_duration\", \"http_req_failed\",\n",
    "               \"vus\", \"node_count\", \"inputTokens\", \"outputTokens\"]\n",
    "\n",
    "    all_results = sorted(all_results, key=lambda x: x[\"data\"][\"time\"])\n",
    "\n",
    "   \n",
    "    first_time = all_results[0][\"data\"][\"time\"]\n",
    "    all_results = [x for x in all_results if x[\"type\"] == \"Point\" and x[\"metric\"] in metrics]\n",
    "    results = []\n",
    "    for result in all_results:\n",
    "        time_from_start = (result[\"data\"][\"time\"] - first_time).total_seconds()\n",
    "        value = result[\"data\"][\"value\"]\n",
    "        metric = result[\"metric\"]\n",
    "        results.append({\n",
    "            \"time_from_start\": time_from_start,\n",
    "            \"value\": value,\n",
    "            \"metric\": metric,\n",
    "            \"gpu\": gpu_name,\n",
    "            \"cpu\": test_config[\"container\"][\"resources\"][\"cpu\"],\n",
    "            \"memory\": test_config[\"container\"][\"resources\"][\"memory\"],\n",
    "        })\n",
    "    \n",
    "    \n",
    "    df = pl.DataFrame(results)\n",
    "    df.sort(\"time_from_start\", multithreaded=True)\n",
    "    df.write_csv(df_file)\n",
    "    return df, cost\n",
    "\n",
    "\n",
    "def get_requests_per_second_by_vu(df):\n",
    "\n",
    "    # First, let's filter for completed HTTP requests\n",
    "    http_requests = df.filter(pl.col(\"metric\") == \"http_req_duration\")\n",
    "\n",
    "    # Get the VU counts at each time point\n",
    "    vu_counts = df.filter(pl.col(\"metric\") == \"vus\")\n",
    "\n",
    "    # Function to count requests per second at each VU level\n",
    "    http_requests_windowed = http_requests.with_columns(\n",
    "        pl.col(\"time_from_start\").floor().alias(\"time_window\")\n",
    "    )\n",
    "    \n",
    "    vu_counts_windowed = vu_counts.with_columns(\n",
    "        pl.col(\"time_from_start\").floor().alias(\"time_window\")\n",
    "    )\n",
    "    \n",
    "    # Get the latest VU count in each window\n",
    "    vu_by_window = vu_counts_windowed.group_by(\"time_window\").agg(\n",
    "        pl.col(\"value\").last().alias(\"vu_count\")\n",
    "    )\n",
    "    \n",
    "    # Count requests in each window\n",
    "    requests_by_window = http_requests_windowed.group_by(\"time_window\").agg(\n",
    "        pl.count().alias(\"request_count\")\n",
    "    )\n",
    "    \n",
    "    # Join the datasets on time window\n",
    "    result = requests_by_window.join(\n",
    "        vu_by_window, on=\"time_window\", how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    # Calculate requests per second per VU\n",
    "    result = result.with_columns(\n",
    "        pl.col(\"request_count\").alias(\"requests_per_second\")\n",
    "    )\n",
    "    \n",
    "    # Group by VU count to get average RPS at each VU level\n",
    "    final_result = result.group_by(\"vu_count\").agg(\n",
    "        pl.col(\"requests_per_second\").mean().alias(\"avg_requests_per_second\"),\n",
    "        pl.col(\"requests_per_second\").count().alias(\"sample_count\")\n",
    "    ).sort(\"vu_count\")\n",
    "    return final_result\n",
    "\n",
    "\n",
    "def get_gpt4o_mini_price(df):\n",
    "  total_input_tokens = df.filter(pl.col(\"metric\") == \"inputTokens\").select(pl.col(\"value\")).sum().item()\n",
    "  total_output_tokens = df.filter(pl.col(\"metric\") == \"outputTokens\").select(pl.col(\"value\")).sum().item()\n",
    "  gpt4o_mini_price = gpt4o_mini_price_per_million[\"input\"] * total_input_tokens * gpt4o_mini_token_multiplier / 1e6 + gpt4o_mini_price_per_million[\"output\"] * total_output_tokens / 1e6\n",
    "  return gpt4o_mini_price\n",
    "\n",
    "\n",
    "def get_throughput_stats(rps_by_vu):\n",
    "  max_throughput_row = rps_by_vu.sort(\"avg_requests_per_second\", descending=True).head(1)\n",
    "\n",
    "  max_throughput = max_throughput_row[\"avg_requests_per_second\"][0]\n",
    "  vus_at_max_throughput = max_throughput_row[\"vu_count\"][0]\n",
    "  return max_throughput, vus_at_max_throughput\n",
    "\n",
    "\n",
    "def process_gpu(gpu):\n",
    "    df, cost = get_df(gpu)\n",
    "    rps_by_vu = get_requests_per_second_by_vu(df)\n",
    "    max_throughput, vus_at_max_throughput = get_throughput_stats(rps_by_vu)\n",
    "    gpt4o_mini_price = get_gpt4o_mini_price(df)\n",
    "    num_images = df.filter(pl.col(\"metric\") == \"http_req_duration\").select(pl.col(\"value\")).count().item()\n",
    "    avg_input_tokens_per_image = df.filter(pl.col(\"metric\") == \"inputTokens\").select(pl.col(\"value\")).mean().item()\n",
    "    test_duration = df.filter(pl.col(\"metric\") == \"http_req_duration\").select(pl.col(\"time_from_start\")).max().item()\n",
    "    max_nodes = df.filter(pl.col(\"metric\") == \"node_count\").select(pl.col(\"value\")).max().item()\n",
    "    cost_of_cluster_per_s = max_nodes * cost[\"batch\"] / 3600\n",
    "    cost_per_image_at_peak_throughput = cost_of_cluster_per_s / max_throughput\n",
    "    cost_of_whole_batch_at_peak_throughput = cost_per_image_at_peak_throughput * num_images\n",
    "    savings_vs_openai = gpt4o_mini_price / cost_of_whole_batch_at_peak_throughput\n",
    "    return {\n",
    "        \"gpu\": gpu,\n",
    "        \"cost\": cost,\n",
    "        \"max_throughput\": max_throughput,\n",
    "        \"vus_at_max_throughput\": vus_at_max_throughput,\n",
    "        \"avg_input_tokens_per_image\": avg_input_tokens_per_image,\n",
    "        \"gpt4o_mini_price\": gpt4o_mini_price,\n",
    "        \"cost_per_image_at_peak_throughput\": cost_per_image_at_peak_throughput,\n",
    "        \"images_per_dollar_at_peak_throughput\": 1 / cost_per_image_at_peak_throughput,\n",
    "        \"cost_of_whole_batch_at_peak_throughput\": cost_of_whole_batch_at_peak_throughput,\n",
    "        \"savings_vs_openai\": savings_vs_openai,\n",
    "        \"test_duration\": test_duration,\n",
    "        \"max_nodes\": max_nodes,\n",
    "        \"num_images\": num_images\n",
    "    }\n",
    "\n",
    "gpus = [\"3090\", \"4080\", \"4090\"]\n",
    "for gpu in gpus:\n",
    "    print(json.dumps(process_gpu(gpu), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_captions(gpu):\n",
    "  caption_file = f\"{gpu}-console.txt\"\n",
    "  with open(caption_file) as f:\n",
    "    for line in f:\n",
    "      content_start = line.find(\"] \") + 2\n",
    "      content = line[content_start:]\n",
    "      parts = content.split(\"|\", 1)\n",
    "      if len(parts) == 2:\n",
    "        url = parts[0].strip()\n",
    "        caption = parts[1].strip().strip('\"')\n",
    "        if len(url) > 0 and len(caption) > 0:\n",
    "          yield url, caption\n",
    "        \n",
    "def captions_to_csv(gpu):\n",
    "  with open(f\"{gpu}-captions.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"url\", \"caption\"])\n",
    "    for url, caption in process_captions(gpu):\n",
    "      writer.writerow([url, caption])\n",
    "      \n",
    "for gpu in gpus:\n",
    "    captions_to_csv(gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
